"""Document indexing pipeline (structure → embeddings → stored nodes)."""

from typing import Iterable

import numpy as np

from .embeddings import EmbeddingModel, JinaEmbeddingModel, average_embeddings
from .text_utils import split_paragraphs, split_sentences
from .types import (
    DocumentPayload,
    NodeKind,
    ParagraphPayload,
    SectionPayload,
    SentencePayload,
    StoredNode,
    TreeNode,
)


def sentence_payloads_from_text(text: str) -> list[SentencePayload]:
    """Split text into sentence payloads using heuristic rules."""
    return [SentencePayload(text=s) for s in split_sentences(text)]


def paragraph_payload_from_text(text: str) -> ParagraphPayload:
    """Convert plain text into a paragraph with sentence segmentation."""
    return ParagraphPayload(
        text=text,
        sentences=sentence_payloads_from_text(text),
    )


def sections_from_text(document: DocumentPayload) -> list[SectionPayload]:
    """Auto-generate a single section from unstructured document text."""
    paragraphs = [
        paragraph_payload_from_text(paragraph)
        for paragraph in split_paragraphs(document.text)
    ]
    return [
        SectionPayload(
            title=document.title,
            paragraphs=paragraphs,
            metadata={"autogenerated": True},
        )
    ]


class DocumentIndexer:
    """Builds hierarchical nodes from DocumentPayloads and embeds them."""

    def __init__(self, embedding_model: EmbeddingModel | None = None) -> None:
        self._embedding_model = embedding_model or JinaEmbeddingModel()

    async def index(self, document: DocumentPayload) -> list[StoredNode]:
        """Build hierarchical tree, compute embeddings, and return storable nodes."""
        root = self._build_tree(document)
        await self._embed_tree(root)
        return [self._to_stored(node) for node in self._flatten(root)]

    def _build_tree(self, document: DocumentPayload) -> TreeNode:
        """Build document → section → paragraph → sentence hierarchy.

        Node IDs follow pattern: doc:sec1:p2:s3 for easy parent lookup.
        """
        # Track global counters for generating unique IDs
        counters = {"section": 0, "paragraph": 0, "sentence": 0}

        # Use provided structure or generate from plain text
        sections = document.sections or sections_from_text(document)

        # Reconstruct full document text if needed
        document_text = document.text or "\n\n".join(
            paragraph.text for section in sections for paragraph in section.paragraphs
        )

        # Build root document node
        root_metadata = dict(document.metadata)
        root_metadata.setdefault("document_id", document.document_id)
        root_metadata.setdefault("document_title", document.title)
        root = TreeNode(
            node_id=document.document_id,
            parent_id=None,
            kind=NodeKind.DOCUMENT,
            title=document.title,
            text=document_text,
            metadata=root_metadata,
        )

        # Build section nodes
        for section in sections:
            counters["section"] += 1
            section_id = f"{document.document_id}:sec{counters['section']}"
            section_meta = dict(section.metadata)
            section_meta.update(
                {
                    "document_id": document.document_id,
                    "document_title": document.title,
                    "section_index": counters["section"],
                }
            )
            section_node = TreeNode(
                node_id=section_id,
                parent_id=root.node_id,
                kind=NodeKind.SECTION,
                title=section.title,
                text=section.title,
                metadata=section_meta,
            )
            root.children.append(section_node)

            # Build paragraph nodes within this section
            for paragraph in section.paragraphs:
                counters["paragraph"] += 1
                paragraph_id = f"{section_id}:p{counters['paragraph']}"
                paragraph_meta = dict(paragraph.metadata)
                paragraph_meta.update(
                    {
                        "document_id": document.document_id,
                        "document_title": document.title,
                        "section_id": section_id,
                        "section_index": counters["section"],
                        "paragraph_index": counters["paragraph"],
                    }
                )
                paragraph_node = TreeNode(
                    node_id=paragraph_id,
                    parent_id=section_id,
                    kind=NodeKind.PARAGRAPH,
                    title=section.title,
                    text=paragraph.text,
                    metadata=paragraph_meta,
                )
                section_node.children.append(paragraph_node)

                # Build sentence nodes within this paragraph
                sentences = paragraph.sentences or sentence_payloads_from_text(
                    paragraph.text
                )
                for sentence in sentences:
                    counters["sentence"] += 1
                    sentence_id = f"{paragraph_id}:s{counters['sentence']}"
                    sentence_meta = dict(sentence.metadata)
                    sentence_meta.update(
                        {
                            "document_id": document.document_id,
                            "document_title": document.title,
                            "section_id": section_id,
                            "paragraph_id": paragraph_id,
                            "sentence_index": counters["sentence"],
                        }
                    )
                    sentence_node = TreeNode(
                        node_id=sentence_id,
                        parent_id=paragraph_id,
                        kind=NodeKind.SENTENCE,
                        title=section.title,
                        text=sentence.text,
                        metadata=sentence_meta,
                    )
                    paragraph_node.children.append(sentence_node)

        return root

    async def _embed_tree(self, root: TreeNode) -> None:
        """Embed leaf nodes and propagate upward to parents."""
        # Batch-embed all leaf nodes (sentences) for efficiency
        leaves = [node for node in self._flatten(root) if not node.children]
        if leaves:
            embeddings = await self._embedding_model.embed(
                [leaf.text for leaf in leaves]
            )
            for leaf, vector in zip(leaves, embeddings, strict=True):
                leaf.embedding = vector

        # Recursively compute parent embeddings from children
        self._propagate_embeddings(root)

    def _propagate_embeddings(self, node: TreeNode) -> np.ndarray:
        """Recursively compute parent embeddings as average of children."""
        if node.embedding is not None:
            return node.embedding  # Already embedded (leaf node)

        # Recurse to children first
        child_vectors = [self._propagate_embeddings(child) for child in node.children]
        if not child_vectors:
            raise ValueError(f"Node {node.node_id} is missing an embedding.")

        # Parent embedding = normalized average of children
        node.embedding = average_embeddings(child_vectors)
        return node.embedding

    def _flatten(self, node: TreeNode) -> Iterable[TreeNode]:
        """Depth-first traversal of tree."""
        yield node
        for child in node.children:
            yield from self._flatten(child)

    def _to_stored(self, node: TreeNode) -> StoredNode:
        """Convert tree node to storable format."""
        if node.embedding is None:
            raise ValueError(f"Node {node.node_id} is missing an embedding.")

        return StoredNode(
            node_id=node.node_id,
            parent_id=node.parent_id,
            kind=node.kind,
            title=node.title,
            text=node.text,
            metadata=node.metadata,
            embedding=node.embedding,
            child_ids=[child.node_id for child in node.children],
        )
