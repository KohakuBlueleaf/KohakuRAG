"""Document indexing pipeline (structure → embeddings → stored nodes)."""

from typing import Iterable

import numpy as np

from .embeddings import EmbeddingModel, JinaEmbeddingModel, average_embeddings
from .text_utils import split_paragraphs, split_sentences
from .types import (
    DocumentPayload,
    NodeKind,
    ParagraphPayload,
    SectionPayload,
    SentencePayload,
    StoredNode,
    TreeNode,
)


def sentence_payloads_from_text(text: str) -> list[SentencePayload]:
    return [SentencePayload(text=s) for s in split_sentences(text)]


def paragraph_payload_from_text(text: str) -> ParagraphPayload:
    return ParagraphPayload(
        text=text,
        sentences=sentence_payloads_from_text(text),
    )


def sections_from_text(document: DocumentPayload) -> list[SectionPayload]:
    paragraphs = [
        paragraph_payload_from_text(paragraph)
        for paragraph in split_paragraphs(document.text)
    ]
    return [
        SectionPayload(
            title=document.title,
            paragraphs=paragraphs,
            metadata={"autogenerated": True},
        )
    ]


class DocumentIndexer:
    """Builds hierarchical nodes from DocumentPayloads and embeds them."""

    def __init__(self, embedding_model: EmbeddingModel | None = None) -> None:
        self._embedding_model = embedding_model or JinaEmbeddingModel()

    def index(self, document: DocumentPayload) -> list[StoredNode]:
        root = self._build_tree(document)
        self._embed_tree(root)
        return [self._to_stored(node) for node in self._flatten(root)]

    def _build_tree(self, document: DocumentPayload) -> TreeNode:
        counters = {"section": 0, "paragraph": 0, "sentence": 0}
        sections = document.sections or sections_from_text(document)
        document_text = document.text or "\n\n".join(
            paragraph.text for section in sections for paragraph in section.paragraphs
        )
        root_metadata = dict(document.metadata)
        root_metadata.setdefault("document_id", document.document_id)
        root_metadata.setdefault("document_title", document.title)
        root = TreeNode(
            node_id=document.document_id,
            parent_id=None,
            kind=NodeKind.DOCUMENT,
            title=document.title,
            text=document_text,
            metadata=root_metadata,
        )
        for section in sections:
            counters["section"] += 1
            section_id = f"{document.document_id}:sec{counters['section']}"
            section_meta = dict(section.metadata)
            section_meta.update(
                {
                    "document_id": document.document_id,
                    "document_title": document.title,
                    "section_index": counters["section"],
                }
            )
            section_node = TreeNode(
                node_id=section_id,
                parent_id=root.node_id,
                kind=NodeKind.SECTION,
                title=section.title,
                text=section.title,
                metadata=section_meta,
            )
            root.children.append(section_node)
            for paragraph in section.paragraphs:
                counters["paragraph"] += 1
                paragraph_id = f"{section_id}:p{counters['paragraph']}"
                paragraph_meta = dict(paragraph.metadata)
                paragraph_meta.update(
                    {
                        "document_id": document.document_id,
                        "document_title": document.title,
                        "section_id": section_id,
                        "section_index": counters["section"],
                        "paragraph_index": counters["paragraph"],
                    }
                )
                paragraph_node = TreeNode(
                    node_id=paragraph_id,
                    parent_id=section_id,
                    kind=NodeKind.PARAGRAPH,
                    title=section.title,
                    text=paragraph.text,
                    metadata=paragraph_meta,
                )
                section_node.children.append(paragraph_node)
                sentences = paragraph.sentences or sentence_payloads_from_text(
                    paragraph.text
                )
                for sentence in sentences:
                    counters["sentence"] += 1
                    sentence_id = f"{paragraph_id}:s{counters['sentence']}"
                    sentence_meta = dict(sentence.metadata)
                    sentence_meta.update(
                        {
                            "document_id": document.document_id,
                            "document_title": document.title,
                            "section_id": section_id,
                            "paragraph_id": paragraph_id,
                            "sentence_index": counters["sentence"],
                        }
                    )
                    sentence_node = TreeNode(
                        node_id=sentence_id,
                        parent_id=paragraph_id,
                        kind=NodeKind.SENTENCE,
                        title=section.title,
                        text=sentence.text,
                        metadata=sentence_meta,
                    )
                    paragraph_node.children.append(sentence_node)
        return root

    def _embed_tree(self, root: TreeNode) -> None:
        leaves = [node for node in self._flatten(root) if not node.children]
        if leaves:
            embeddings = self._embedding_model.embed([leaf.text for leaf in leaves])
            for leaf, vector in zip(leaves, embeddings, strict=True):
                leaf.embedding = vector
        self._propagate_embeddings(root)

    def _propagate_embeddings(self, node: TreeNode) -> np.ndarray:
        if node.embedding is not None:
            return node.embedding
        child_vectors = [self._propagate_embeddings(child) for child in node.children]
        if not child_vectors:
            raise ValueError(f"Node {node.node_id} is missing an embedding.")
        node.embedding = average_embeddings(child_vectors)
        return node.embedding

    def _flatten(self, node: TreeNode) -> Iterable[TreeNode]:
        yield node
        for child in node.children:
            yield from self._flatten(child)

    def _to_stored(self, node: TreeNode) -> StoredNode:
        if node.embedding is None:
            raise ValueError(f"Node {node.node_id} is missing an embedding.")
        return StoredNode(
            node_id=node.node_id,
            parent_id=node.parent_id,
            kind=node.kind,
            title=node.title,
            text=node.text,
            metadata=node.metadata,
            embedding=node.embedding,
            child_ids=[child.node_id for child in node.children],
        )
